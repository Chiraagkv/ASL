{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experimentation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNa6XNup0HCKqXuyE6PBF3h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiraagkv/ASL/blob/main/experimentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYQk8XcxVdt0"
      },
      "source": [
        "# ASL to Text\n",
        "An application to convert sign language to text.\n",
        "\n",
        "## 1. Problem Defination\n",
        "\n",
        "Everyone cannot understand sign language, to help everyone to read sign language, an AI based solution to convert sign language to text will be ideal solution.\n",
        "\n",
        "## 2. Data\n",
        "\n",
        "Using [ASL Alphabet dataset](https://www.kaggle.com/grassknoted/asl-alphabet) from [Kaggle.com](https://www.kaggle.com)\n",
        "\n",
        "in the form of data we have Images (unstructured data).\n",
        "\n",
        "The data structure is:\n",
        "\n",
        "```bash\n",
        "+- asl_alphabet_test \n",
        "| +- asl_alphabet_test\n",
        "| | +- images.jpg\n",
        "|\n",
        "+- asl_alphabet_train\n",
        "| +- asl_alphabet_train\n",
        "| | +- <CLASSNAME>\n",
        "| | | +- images.jpg\n",
        "```\n",
        "\n",
        "## 3. Evaluation\n",
        "\n",
        "As our problem is multiclass classification, we will be using evaluation methods for multi-class classification\n",
        "\n",
        "## 4. Features\n",
        "\n",
        "* Unstructured Data\n",
        "* 29 classes/different signs\n",
        "* about 87K images in the train folder (total)\n",
        "* 28 images for the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad6zvc6YavJG"
      },
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJwvp7kIbQ_v"
      },
      "source": [
        "download the datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH0Aig3SboSj"
      },
      "source": [
        "!pip install kaggle  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKT4fJdObrx0",
        "outputId": "bffae09b-f532-4dd9-dba3-c167d556614d"
      },
      "source": [
        "!mkdir /root/.kaggle/\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "!echo '{\"username\":\"yashpawarp\",\"key\":\"bf231966c472597c9b7dfd0c64730dc9\"}' > /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d grassknoted/asl-alphabet --unzip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle/’: File exists\n",
            "Downloading asl-alphabet.zip to /content\n",
            " 99% 1.02G/1.03G [00:08<00:00, 139MB/s]\n",
            "100% 1.03G/1.03G [00:09<00:00, 122MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtMtFUuKb64F"
      },
      "source": [
        "Unzip the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6AVUH8Ac6zr"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/asl-alphabet.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiyKnBjUdMJj"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dqGlTjJhE6Y"
      },
      "source": [
        "def unbatchify(batch):\n",
        "    '''\n",
        "    Takes a batched dataset of (image, label) Tensors and returns separate arrays of imags and labels\n",
        "    '''\n",
        "    images = []\n",
        "    labels = []\n",
        "    # Loop through batched data\n",
        "    for image, label in batch.unbatch().as_numpy_iterator():\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFPMRiVnhAun",
        "outputId": "e0ddce45-678f-40d5-a704-c818ac95773b"
      },
      "source": [
        "data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/asl_alphabet_train/asl_alphabet_train',  # data directory\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\"\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 87000 files belonging to 29 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNXAMLR7hOHJ"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "def stratify_split(X, y, test_size):\n",
        "    \"\"\"\n",
        "    Split the data using StratifiedShuffleSplit\n",
        "    \"\"\"\n",
        "    split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
        "\n",
        "    for train_index, test_index in split.split(X, y):\n",
        "        X_train, y_train = X[train_index], y[train_index]\n",
        "        X_test, y_test = X[test_index], y[test_index]\n",
        "\n",
        "    return X_train, y_trian, X_test, y_test"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc6rI989hKFZ"
      },
      "source": [
        "# unbatchify crashes the session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQt1_-P2ioiJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}